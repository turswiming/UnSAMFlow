#!/usr/bin/env python3
"""
Test script for FlowSmoothLoss BMM optimization
æµ‹è¯•FlowSmoothLoss BMMä¼˜åŒ–çš„è„šæœ¬
"""

import torch
import torch.nn as nn
import time
import numpy as np
from losses.FlowSmoothLoss import FlowSmoothLoss
import os
import sys

def create_test_data(batch_size, height, width, device):
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    # åˆ›å»ºflowæ•°æ®
    flows = []
    for b in range(batch_size):
        # åˆ›å»ºå¹³æ»‘çš„flowåœº
        x = torch.linspace(-1, 1, width, device=device)
        y = torch.linspace(-1, 1, height, device=device)
        X, Y = torch.meshgrid(x, y, indexing='xy')
        
        # åˆ›å»ºç®€å•çš„çº¿æ€§flow
        flow_x = 0.1 * X + 0.05 * Y
        flow_y = -0.05 * X + 0.1 * Y
        
        flow = torch.stack([flow_x, flow_y], dim=0)  # (2, H, W)
        flows.append(flow)
    
    flows_tensor = torch.stack(flows, dim=0)  # (B, 2, H, W)
    
    # åˆ›å»ºmaskæ•°æ®
    masks = []
    for b in range(batch_size):
        # åˆ›å»ºç®€å•çš„åˆ†å‰²mask
        mask1 = torch.zeros(height, width, device=device)
        mask2 = torch.zeros(height, width, device=device)
        
        # ç¬¬ä¸€ä¸ªmaskè¦†ç›–å·¦åŠéƒ¨åˆ†
        mask1[:, :width//2] = 1.0
        # ç¬¬äºŒä¸ªmaskè¦†ç›–å³åŠéƒ¨åˆ†
        mask2[:, width//2:] = 1.0
        
        # æ·»åŠ ä¸€äº›å™ªå£°ä½¿å…¶æ›´çœŸå®
        mask1 += torch.randn_like(mask1) * 0.1
        mask2 += torch.randn_like(mask2) * 0.1
        
        # ç¡®ä¿maskæ˜¯æ¦‚ç‡åˆ†å¸ƒ
        mask = torch.stack([mask1, mask2], dim=0)
        mask = torch.softmax(mask, dim=0)
        masks.append(mask)
    
    masks_tensor = torch.stack(masks, dim=0)  # (B, 2, H, W)
    
    # åˆ›å»ºå›¾åƒæ•°æ®
    img_tensor = torch.randn(batch_size, 3, height, width, device=device)
    
    return flows_tensor, masks_tensor, img_tensor

def test_bmm_optimization():
    """æµ‹è¯•BMMä¼˜åŒ–çš„æ€§èƒ½æå‡"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ FlowSmoothLoss BMMä¼˜åŒ–æ€§èƒ½æµ‹è¯• / FlowSmoothLoss BMM Optimization Performance Test")
    print(f"{'='*60}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡ / Using device: {device}")
    
    # æµ‹è¯•ä¸åŒé…ç½®
    test_configs = [
        {"batch_size": 1, "height": 192, "width": 416, "name": "Small"},
        {"batch_size": 2, "height": 384, "width": 832, "name": "Medium"},
        {"batch_size": 4, "height": 384, "width": 832, "name": "Large"},
    ]
    
    flow_smooth_loss = FlowSmoothLoss(device)
    
    for config in test_configs:
        print(f"\nğŸ“Š æµ‹è¯•é…ç½® / Test config: {config['name']}")
        print(f"  Batch size: {config['batch_size']}")
        print(f"  Resolution: {config['height']}x{config['width']}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        flows, masks, imgs = create_test_data(
            config['batch_size'], 
            config['height'], 
            config['width'], 
            device
        )
        
        # é¢„çƒ­
        print(f"  ğŸ”¥ é¢„çƒ­ä¸­ / Warming up...")
        for _ in range(3):
            try:
                flows_list = [flows]
                flows_list[0].requires_grad_(True)
                with torch.enable_grad():
                    loss = flow_smooth_loss(flows_list, imgs, imgs, masks)
                    if isinstance(loss, torch.Tensor):
                        loss.backward()
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
            except Exception as e:
                print(f"    âš ï¸ é¢„çƒ­å¤±è´¥ / Warmup failed: {e}")
                break
        
        # æ€§èƒ½æµ‹è¯•
        print(f"  â±ï¸ æ€§èƒ½æµ‹è¯•ä¸­ / Performance testing...")
        num_runs = 20
        forward_times = []
        backward_times = []
        total_times = []
        successful_runs = 0
        
        for i in range(num_runs):
            try:
                # é‡æ–°åˆ›å»ºæ•°æ®ä»¥ç¡®ä¿æ¢¯åº¦è®¡ç®—æ­£ç¡®
                flows_list = [flows.clone()]
                flows_list[0].requires_grad_(True)
                
                # å‰å‘ä¼ æ’­
                forward_start = time.time()
                with torch.enable_grad():
                    loss = flow_smooth_loss(flows_list, imgs, imgs, masks)
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                forward_end = time.time()
                
                # åå‘ä¼ æ’­
                backward_start = time.time()
                if isinstance(loss, torch.Tensor):
                    loss.backward()
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                backward_end = time.time()
                
                end_time = time.time()
                
                # è®°å½•æ—¶é—´
                forward_time = (forward_end - forward_start) * 1000  # ms
                backward_time = (backward_end - backward_start) * 1000  # ms
                total_time = (end_time - forward_start) * 1000  # ms
                
                forward_times.append(forward_time)
                backward_times.append(backward_time)
                total_times.append(total_time)
                successful_runs += 1
                
                if (i + 1) % 5 == 0:
                    print(f"    å®Œæˆ {i+1}/{num_runs} æ¬¡æµ‹è¯• / Completed {i+1}/{num_runs} tests")
                    
            except Exception as e:
                print(f"    âš ï¸ ç¬¬ {i+1} æ¬¡æµ‹è¯•å¤±è´¥ / Test {i+1} failed: {e}")
                continue
        
        if successful_runs == 0:
            print(f"    âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº† / All tests failed")
            continue
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        forward_mean = np.mean(forward_times)
        forward_std = np.std(forward_times)
        backward_mean = np.mean(backward_times)
        backward_std = np.std(backward_times)
        total_mean = np.mean(total_times)
        total_std = np.std(total_times)
        
        print(f"  ğŸ“ˆ æ€§èƒ½ç»“æœ / Performance results:")
        print(f"    å‰å‘ä¼ æ’­ / Forward pass: {forward_mean:.2f} Â± {forward_std:.2f} ms")
        print(f"    åå‘ä¼ æ’­ / Backward pass: {backward_mean:.2f} Â± {backward_std:.2f} ms")
        print(f"    æ€»æ—¶é—´ / Total time: {total_mean:.2f} Â± {total_std:.2f} ms")
        print(f"    æˆåŠŸç‡ / Success rate: {successful_runs}/{num_runs} ({100*successful_runs/num_runs:.1f}%)")

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print(f"\n{'='*60}")
    print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯• / Memory Usage Test")
    print(f"{'='*60}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    flow_smooth_loss = FlowSmoothLoss(device)
    
    if torch.cuda.is_available():
        # æµ‹è¯•GPUå†…å­˜ä½¿ç”¨
        batch_size, height, width = 2, 384, 832
        flows, masks, imgs = create_test_data(batch_size, height, width, device)
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
        
        # è®°å½•åˆå§‹å†…å­˜
        initial_memory = torch.cuda.memory_allocated() / 1024**2  # MB
        
        # è¿è¡Œå‰å‘ä¼ æ’­
        flows_list = [flows]
        flows_list[0].requires_grad_(True)
        with torch.enable_grad():
            loss = flow_smooth_loss(flows_list, imgs, imgs, masks)
        
        # è®°å½•å³°å€¼å†…å­˜
        peak_memory = torch.cuda.max_memory_allocated() / 1024**2  # MB
        current_memory = torch.cuda.memory_allocated() / 1024**2  # MB
        
        print(f"GPUå†…å­˜ä½¿ç”¨æƒ…å†µ / GPU memory usage:")
        print(f"  åˆå§‹å†…å­˜ / Initial memory: {initial_memory:.2f} MB")
        print(f"  å³°å€¼å†…å­˜ / Peak memory: {peak_memory:.2f} MB")
        print(f"  å½“å‰å†…å­˜ / Current memory: {current_memory:.2f} MB")
        print(f"  å†…å­˜å¢é•¿ / Memory increase: {peak_memory - initial_memory:.2f} MB")
    else:
        print(f"CPUæ¨¡å¼ä¸‹æ— æ³•æµ‹è¯•GPUå†…å­˜ä½¿ç”¨ / Cannot test GPU memory usage in CPU mode")

def test_numerical_stability():
    """æµ‹è¯•æ•°å€¼ç¨³å®šæ€§"""
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ æ•°å€¼ç¨³å®šæ€§æµ‹è¯• / Numerical Stability Test")
    print(f"{'='*60}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    flow_smooth_loss = FlowSmoothLoss(device)
    
    # æµ‹è¯•ä¸åŒå¤§å°çš„æ•°æ®
    test_sizes = [(96, 208), (192, 416), (384, 832)]
    
    for height, width in test_sizes:
        print(f"\nğŸ“ æµ‹è¯•å°ºå¯¸ / Test size: {height}x{width}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        flows, masks, imgs = create_test_data(1, height, width, device)
        
        # æµ‹è¯•å¤šæ¬¡è¿è¡Œçš„ä¸€è‡´æ€§
        losses = []
        for i in range(10):
            try:
                flows_list = [flows.clone()]
                flows_list[0].requires_grad_(True)
                with torch.enable_grad():
                    loss = flow_smooth_loss(flows_list, imgs, imgs, masks)
                if isinstance(loss, torch.Tensor):
                    losses.append(loss.item())
                else:
                    losses.append(float(loss))
            except Exception as e:
                print(f"  âš ï¸ ç¬¬ {i+1} æ¬¡è¿è¡Œå¤±è´¥ / Run {i+1} failed: {e}")
                continue
        
        if len(losses) > 0:
            loss_mean = np.mean(losses)
            loss_std = np.std(losses)
            loss_cv = loss_std / loss_mean if loss_mean != 0 else float('inf')
            
            print(f"  æŸå¤±å‡å€¼ / Loss mean: {loss_mean:.6f}")
            print(f"  æŸå¤±æ ‡å‡†å·® / Loss std: {loss_std:.6f}")
            print(f"  å˜å¼‚ç³»æ•° / Coefficient of variation: {loss_cv:.6f}")
            
            if loss_cv < 0.1:
                print(f"  âœ… æ•°å€¼ç¨³å®š / Numerically stable")
            else:
                print(f"  âš ï¸ æ•°å€¼ä¸ç¨³å®š / Numerically unstable")

def main():
    """ä¸»å‡½æ•°"""
    print(f"ğŸš€ FlowSmoothLoss BMMä¼˜åŒ–æµ‹è¯•å¼€å§‹ / FlowSmoothLoss BMM Optimization Test Started")
    
    # æµ‹è¯•BMMä¼˜åŒ–æ€§èƒ½
    test_bmm_optimization()
    
    # æµ‹è¯•å†…å­˜ä½¿ç”¨
    test_memory_usage()
    
    # æµ‹è¯•æ•°å€¼ç¨³å®šæ€§
    test_numerical_stability()
    
    print(f"\n{'='*60}")
    print(f"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ / All tests completed")
    print(f"{'='*60}")

if __name__ == "__main__":
    main() 