#!/usr/bin/env python3
"""
Test script for FlowSmoothLoss backward propagation timing
ä¸“é—¨æµ‹è¯•FlowSmoothLossåå‘ä¼ æ’­æ—¶é—´çš„è„šæœ¬
"""

import torch
import torch.nn as nn
import time
import numpy as np
from losses.FlowSmoothLoss import FlowSmoothLoss
from models.swin_unet import SwinUNet
from models.get_model import get_mask_model
from utils.config_parser import init_config

def create_stable_flow_data(batch_size, height, width, device):
    """åˆ›å»ºç¨³å®šçš„flowæ•°æ®ï¼Œé¿å…æ•°å€¼é—®é¢˜"""
    # åˆ›å»ºæ›´ç¨³å®šçš„flowæ•°æ®
    flows = []
    for b in range(batch_size):
        # åˆ›å»ºå¹³æ»‘çš„flowåœº
        x = torch.linspace(-1, 1, width, device=device)
        y = torch.linspace(-1, 1, height, device=device)
        X, Y = torch.meshgrid(x, y, indexing='xy')
        
        # åˆ›å»ºç®€å•çš„çº¿æ€§flow
        flow_x = 0.1 * X + 0.05 * Y
        flow_y = -0.05 * X + 0.1 * Y
        
        flow = torch.stack([flow_x, flow_y], dim=0)  # (2, H, W)
        flows.append(flow)
    
    return torch.stack(flows, dim=0)  # (B, 2, H, W)

def create_stable_mask_data(batch_size, height, width, device):
    """åˆ›å»ºç¨³å®šçš„maskæ•°æ®"""
    masks = []
    for b in range(batch_size):
        # åˆ›å»ºç®€å•çš„åˆ†å‰²mask
        mask1 = torch.zeros(height, width, device=device)
        mask2 = torch.zeros(height, width, device=device)
        
        # ç¬¬ä¸€ä¸ªmaskè¦†ç›–å·¦åŠéƒ¨åˆ†
        mask1[:, :width//2] = 1.0
        # ç¬¬äºŒä¸ªmaskè¦†ç›–å³åŠéƒ¨åˆ†
        mask2[:, width//2:] = 1.0
        
        # æ·»åŠ ä¸€äº›å™ªå£°ä½¿å…¶æ›´çœŸå®
        mask1 += torch.randn_like(mask1) * 0.1
        mask2 += torch.randn_like(mask2) * 0.1
        
        # ç¡®ä¿maskæ˜¯æ¦‚ç‡åˆ†å¸ƒ
        mask = torch.stack([mask1, mask2], dim=0)
        mask = torch.softmax(mask, dim=0)
        masks.append(mask)
    
    return torch.stack(masks, dim=0)  # (B, 2, H, W)

def test_flow_smooth_loss_backward_timing():
    """æµ‹è¯•FlowSmoothLossåå‘ä¼ æ’­æ—¶é—´"""
    print("=" * 80)
    print("ğŸš€ FlowSmoothLoss åå‘ä¼ æ’­æ—¶é—´æµ‹è¯• / FlowSmoothLoss Backward Propagation Timing Test")
    print("=" * 80)
    
    # æ£€æŸ¥è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡ / Using device: {device}")
    
    # åˆ›å»ºFlowSmoothLoss
    flow_smooth_loss = FlowSmoothLoss(device)
    print(f"âœ… æˆåŠŸåˆ›å»ºFlowSmoothLoss / Successfully created FlowSmoothLoss")
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹
    try:
        config = init_config("configs/sintel_swin_unet.json")
        model = get_mask_model(config.mask_model)
        model = model.to(device)
        print(f"âœ… æˆåŠŸä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹ / Successfully loaded model from config")
        print(f"æ¨¡å‹ç±»å‹ / Model type: {type(model).__name__}")
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ / Failed to load config: {e}")
        # ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹
        model = SwinUNet(
            img_size=[384, 832],
            in_channels=3,
            out_channels=2,
            embed_dim=96,
            depths=[2, 2, 6, 2],
            num_heads=[3, 6, 12, 24],
            window_size=4
        ).to(device)
        print(f"âœ… ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹ / Created model with default config")
    
    # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    model.train()
    
    # æµ‹è¯•ä¸åŒçš„batch sizeå’Œè¾“å…¥å°ºå¯¸
    test_configs = [
        {"batch_size": 1, "height": 384, "width": 832, "name": "1x384x832"},
        {"batch_size": 2, "height": 384, "width": 832, "name": "2x384x832"},
        {"batch_size": 4, "height": 384, "width": 832, "name": "4x384x832"},
    ]
    
    results = []
    
    for config in test_configs:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•é…ç½® / Test config: {config['name']}")
        print(f"{'='*60}")
        
        # åˆ›å»ºè¾“å…¥æ•°æ®
        input_tensor = torch.randn(
            config['batch_size'], 3, config['height'], config['width']
        ).to(device)
        
        # åˆ›å»ºç¨³å®šçš„flowæ•°æ®
        flows_12 = [create_stable_flow_data(config['batch_size'], config['height'], config['width'], device)]
        flows_12[0].requires_grad_(True)
        
        # åˆ›å»ºç¨³å®šçš„maskæ•°æ®
        mask = create_stable_mask_data(config['batch_size'], config['height'], config['width'], device)
        
        print(f"è¾“å…¥å°ºå¯¸ / Input shape: {input_tensor.shape}")
        print(f"Flowå°ºå¯¸ / Flow shape: {flows_12[0].shape}")
        print(f"Maskå°ºå¯¸ / Mask shape: {mask.shape}")
        print(f"Flow requires_grad: {flows_12[0].requires_grad}")
        
        # é¢„çƒ­
        print("ğŸ”¥ é¢„çƒ­ä¸­ / Warming up...")
        for _ in range(3):
            try:
                with torch.enable_grad():
                    loss = flow_smooth_loss(flows_12, input_tensor, input_tensor, mask)
                    loss.backward()
            except Exception as e:
                print(f"âš ï¸ é¢„çƒ­æ—¶å‡ºç°é”™è¯¯ / Error during warmup: {e}")
                break
        
        # åŒæ­¥GPU
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        
        # æµ‹è¯•å¤šæ¬¡å¹¶è®°å½•æ—¶é—´
        num_runs = 10
        forward_times = []
        backward_times = []
        total_times = []
        
        print(f"ğŸ”„ å¼€å§‹æµ‹è¯• {num_runs} æ¬¡ / Starting {num_runs} test runs...")
        
        successful_runs = 0
        for i in range(num_runs):
            try:
                # é‡æ–°åˆ›å»ºç¨³å®šçš„flowæ•°æ®
                flows_12 = [create_stable_flow_data(config['batch_size'], config['height'], config['width'], device)]
                flows_12[0].requires_grad_(True)
                
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # å‰å‘ä¼ æ’­
                forward_start = time.time()
                with torch.enable_grad():
                    loss = flow_smooth_loss(flows_12, input_tensor, input_tensor, mask)
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                forward_end = time.time()
                
                # åå‘ä¼ æ’­
                backward_start = time.time()
                loss.backward()
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                backward_end = time.time()
                
                end_time = time.time()
                
                # è®°å½•æ—¶é—´
                forward_time = (forward_end - forward_start) * 1000  # ms
                backward_time = (backward_end - backward_start) * 1000  # ms
                total_time = (end_time - start_time) * 1000  # ms
                
                forward_times.append(forward_time)
                backward_times.append(backward_time)
                total_times.append(total_time)
                successful_runs += 1
                
                if (i + 1) % 5 == 0:
                    print(f"  å®Œæˆ {i+1}/{num_runs} æ¬¡æµ‹è¯• / Completed {i+1}/{num_runs} tests")
                    
            except Exception as e:
                print(f"âš ï¸ ç¬¬ {i+1} æ¬¡æµ‹è¯•å¤±è´¥ / Test {i+1} failed: {e}")
                continue
        
        if successful_runs == 0:
            print(f"âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº† / All tests failed")
            continue
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        forward_mean = np.mean(forward_times)
        forward_std = np.std(forward_times)
        backward_mean = np.mean(backward_times)
        backward_std = np.std(backward_times)
        total_mean = np.mean(total_times)
        total_std = np.std(total_times)
        
        # è®¡ç®—FPS
        fps = 1000 / total_mean
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ / Test Results (æˆåŠŸ {successful_runs}/{num_runs} æ¬¡):")
        print(f"  å‰å‘ä¼ æ’­æ—¶é—´ / Forward time: {forward_mean:.2f} Â± {forward_std:.2f} ms")
        print(f"  åå‘ä¼ æ’­æ—¶é—´ / Backward time: {backward_mean:.2f} Â± {backward_std:.2f} ms")
        print(f"  æ€»æ—¶é—´ / Total time: {total_mean:.2f} Â± {total_std:.2f} ms")
        print(f"  FPS: {fps:.2f}")
        print(f"  åå‘ä¼ æ’­å æ¯” / Backward ratio: {(backward_mean/total_mean)*100:.1f}%")
        
        # è®°å½•ç»“æœ
        results.append({
            'config': config['name'],
            'forward_mean': forward_mean,
            'forward_std': forward_std,
            'backward_mean': backward_mean,
            'backward_std': backward_std,
            'total_mean': total_mean,
            'total_std': total_std,
            'fps': fps,
            'backward_ratio': (backward_mean/total_mean)*100,
            'successful_runs': successful_runs
        })
    
    # æ‰“å°æ€»ç»“
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ æµ‹è¯•æ€»ç»“ / Test Summary")
    print(f"{'='*80}")
    
    print(f"{'é…ç½®':<15} {'å‰å‘(ms)':<12} {'åå‘(ms)':<12} {'æ€»è®¡(ms)':<12} {'FPS':<8} {'åå‘å æ¯”':<10} {'æˆåŠŸç‡':<8}")
    print(f"{'Config':<15} {'Forward':<12} {'Backward':<12} {'Total':<12} {'FPS':<8} {'Bwd%':<10} {'Success':<8}")
    print("-" * 90)
    
    for result in results:
        print(f"{result['config']:<15} "
              f"{result['forward_mean']:<12.2f} "
              f"{result['backward_mean']:<12.2f} "
              f"{result['total_mean']:<12.2f} "
              f"{result['fps']:<8.2f} "
              f"{result['backward_ratio']:<10.1f}% "
              f"{result['successful_runs']:<8}")
    
    # å†…å­˜ä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / 1024**2  # MB
        memory_reserved = torch.cuda.memory_reserved() / 1024**2  # MB
        print(f"\nğŸ’¾ GPUå†…å­˜ä½¿ç”¨ / GPU Memory Usage:")
        print(f"  å·²åˆ†é… / Allocated: {memory_allocated:.2f} MB")
        print(f"  å·²ä¿ç•™ / Reserved: {memory_reserved:.2f} MB")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ / Test completed!")
    return results

def test_flow_smooth_loss_components():
    """æµ‹è¯•FlowSmoothLossçš„å„ä¸ªç»„ä»¶æ—¶é—´"""
    print(f"\n{'='*60}")
    print(f"ğŸ”§ FlowSmoothLossç»„ä»¶æ—¶é—´æµ‹è¯• / FlowSmoothLoss Component Timing Test")
    print(f"{'='*60}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    flow_smooth_loss = FlowSmoothLoss(device)
    
    # æµ‹è¯•æ•°æ®
    batch_size = 2
    height, width = 384, 832
    flows_12 = [create_stable_flow_data(batch_size, height, width, device)]
    flows_12[0].requires_grad_(True)
    input_tensor = torch.randn(batch_size, 3, height, width).to(device)
    mask = create_stable_mask_data(batch_size, height, width, device)
    
    print(f"æµ‹è¯•æ•°æ®å°ºå¯¸ / Test data shapes:")
    print(f"  Flow: {flows_12[0].shape}")
    print(f"  Input: {input_tensor.shape}")
    print(f"  Mask: {mask.shape}")
    
    # æµ‹è¯•embeddingæ„å»ºæ—¶é—´
    print(f"\nğŸ”§ æµ‹è¯•embeddingæ„å»ºæ—¶é—´ / Testing embedding construction time...")
    num_runs = 10
    embedding_times = []
    
    for i in range(num_runs):
        start_time = time.time()
        embedding = flow_smooth_loss.construct_embedding((height, width))
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        end_time = time.time()
        embedding_times.append((end_time - start_time) * 1000)
    
    embedding_mean = np.mean(embedding_times)
    embedding_std = np.std(embedding_times)
    print(f"  Embeddingæ„å»ºæ—¶é—´ / Embedding construction time: {embedding_mean:.2f} Â± {embedding_std:.2f} ms")
    

def test_flow_smooth_loss_memory():
    """æµ‹è¯•FlowSmoothLosså†…å­˜ä½¿ç”¨"""
    print(f"\n{'='*60}")
    print(f"ğŸ’¾ FlowSmoothLosså†…å­˜æµ‹è¯• / FlowSmoothLoss Memory Test")
    print(f"{'='*60}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    if not torch.cuda.is_available():
        print("âŒ éœ€è¦GPUè¿›è¡Œå†…å­˜æµ‹è¯• / GPU required for memory test")
        return
    
    # æ¸…ç©ºGPUç¼“å­˜
    torch.cuda.empty_cache()
    
    flow_smooth_loss = FlowSmoothLoss(device)
    
    # æµ‹è¯•ä¸åŒbatch sizeçš„å†…å­˜ä½¿ç”¨
    batch_sizes = [1, 2, 4, 8]
    
    for batch_size in batch_sizes:
        try:
            # æ¸…ç©ºç¼“å­˜
            torch.cuda.empty_cache()
            
            # åˆ›å»ºæ•°æ®
            flows_12 = [create_stable_flow_data(batch_size, 384, 832, device)]
            flows_12[0].requires_grad_(True)
            input_tensor = torch.randn(batch_size, 3, 384, 832).to(device)
            mask = create_stable_mask_data(batch_size, 384, 832, device)
            
            # è®°å½•å†…å­˜ä½¿ç”¨
            memory_before = torch.cuda.memory_allocated() / 1024**2
            
            # å‰å‘ä¼ æ’­
            with torch.enable_grad():
                loss = flow_smooth_loss(flows_12, input_tensor, input_tensor, mask)
            memory_after_forward = torch.cuda.memory_allocated() / 1024**2
            
            # åå‘ä¼ æ’­
            loss.backward()
            memory_after_backward = torch.cuda.memory_allocated() / 1024**2
            
            print(f"Batch size {batch_size}:")
            print(f"  å‰å‘ä¼ æ’­å†…å­˜ / Forward memory: {memory_after_forward - memory_before:.2f} MB")
            print(f"  åå‘ä¼ æ’­å†…å­˜ / Backward memory: {memory_after_backward - memory_after_forward:.2f} MB")
            print(f"  æ€»å†…å­˜ / Total memory: {memory_after_backward:.2f} MB")
            
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"âŒ Batch size {batch_size}: GPUå†…å­˜ä¸è¶³ / Out of GPU memory")
                break
            else:
                print(f"âŒ Batch size {batch_size}: {e}")

def test_flow_smooth_loss_vs_other_losses():
    """æ¯”è¾ƒFlowSmoothLossä¸å…¶ä»–æŸå¤±å‡½æ•°çš„æ—¶é—´"""
    print(f"\n{'='*60}")
    print(f"âš–ï¸ æŸå¤±å‡½æ•°æ—¶é—´æ¯”è¾ƒ / Loss Function Timing Comparison")
    print(f"{'='*60}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åˆ›å»ºä¸åŒçš„æŸå¤±å‡½æ•°
    flow_smooth_loss = FlowSmoothLoss(device)
    mse_loss = nn.MSELoss()
    l1_loss = nn.L1Loss()
    
    # æµ‹è¯•æ•°æ®
    batch_size = 2
    flows_12 = [create_stable_flow_data(batch_size, 384, 832, device)]
    flows_12[0].requires_grad_(True)
    input_tensor = torch.randn(batch_size, 3, 384, 832).to(device)
    mask = create_stable_mask_data(batch_size, 384, 832, device)
    
    # åˆ›å»ºç›®æ ‡æ•°æ®
    target = create_stable_flow_data(batch_size, 384, 832, device)
    target.requires_grad_(True)
    
    num_runs = 10
    loss_functions = [
        ("FlowSmoothLoss", flow_smooth_loss, lambda: flow_smooth_loss(flows_12, input_tensor, input_tensor, mask)),
        ("MSE Loss", mse_loss, lambda: mse_loss(flows_12[0], target)),
        ("L1 Loss", l1_loss, lambda: l1_loss(flows_12[0], target))
    ]
    
    results = []
    
    for name, loss_func, loss_compute in loss_functions:
        print(f"\nğŸ”§ æµ‹è¯• {name} / Testing {name}...")
        
        # é¢„çƒ­
        for _ in range(3):
            try:
                with torch.enable_grad():
                    loss = loss_compute()
                    loss.backward()
            except Exception as e:
                print(f"âš ï¸ é¢„çƒ­æ—¶å‡ºç°é”™è¯¯ / Error during warmup: {e}")
                break
        
        # æµ‹è¯•æ—¶é—´
        forward_times = []
        backward_times = []
        successful_runs = 0
        
        for i in range(num_runs):
            try:
                # é‡æ–°åˆ›å»ºæ•°æ®ä»¥ç¡®ä¿æ¢¯åº¦è®¡ç®—æ­£ç¡®
                if name == "FlowSmoothLoss":
                    flows_12 = [create_stable_flow_data(batch_size, 384, 832, device)]
                    flows_12[0].requires_grad_(True)
                    loss_compute = lambda: flow_smooth_loss(flows_12, input_tensor, input_tensor, mask)
                else:
                    flows_12 = [create_stable_flow_data(batch_size, 384, 832, device)]
                    flows_12[0].requires_grad_(True)
                    target = create_stable_flow_data(batch_size, 384, 832, device)
                    target.requires_grad_(True)
                    if name == "MSE Loss":
                        loss_compute = lambda: mse_loss(flows_12[0], target)
                    else:
                        loss_compute = lambda: l1_loss(flows_12[0], target)
                
                # å‰å‘ä¼ æ’­
                forward_start = time.time()
                with torch.enable_grad():
                    loss = loss_compute()
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                forward_end = time.time()
                
                # åå‘ä¼ æ’­
                backward_start = time.time()
                loss.backward()
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                backward_end = time.time()
                
                forward_times.append((forward_end - forward_start) * 1000)
                backward_times.append((backward_end - backward_start) * 1000)
                successful_runs += 1
                
            except Exception as e:
                print(f"âš ï¸ ç¬¬ {i+1} æ¬¡æµ‹è¯•å¤±è´¥ / Test {i+1} failed: {e}")
                continue
        
        if successful_runs == 0:
            print(f"âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº† / All tests failed")
            continue
        
        forward_mean = np.mean(forward_times)
        backward_mean = np.mean(backward_times)
        total_mean = forward_mean + backward_mean
        
        print(f"  å‰å‘ä¼ æ’­ / Forward: {forward_mean:.2f} ms")
        print(f"  åå‘ä¼ æ’­ / Backward: {backward_mean:.2f} ms")
        print(f"  æ€»æ—¶é—´ / Total: {total_mean:.2f} ms")
        print(f"  æˆåŠŸç‡ / Success rate: {successful_runs}/{num_runs}")
        
        results.append({
            'name': name,
            'forward': forward_mean,
            'backward': backward_mean,
            'total': total_mean,
            'successful_runs': successful_runs
        })
    
    # æ‰“å°æ¯”è¾ƒç»“æœ
    print(f"\nğŸ“Š æŸå¤±å‡½æ•°æ—¶é—´æ¯”è¾ƒ / Loss function timing comparison:")
    print(f"{'æŸå¤±å‡½æ•°':<15} {'å‰å‘(ms)':<12} {'åå‘(ms)':<12} {'æ€»è®¡(ms)':<12} {'æˆåŠŸç‡':<8}")
    print(f"{'Loss Function':<15} {'Forward':<12} {'Backward':<12} {'Total':<12} {'Success':<8}")
    print("-" * 70)
    
    for result in results:
        print(f"{result['name']:<15} "
              f"{result['forward']:<12.2f} "
              f"{result['backward']:<12.2f} "
              f"{result['total']:<12.2f} "
              f"{result['successful_runs']:<8}")

if __name__ == "__main__":
    # è¿è¡ŒFlowSmoothLossåå‘ä¼ æ’­æ—¶é—´æµ‹è¯•
    results = test_flow_smooth_loss_backward_timing()
    
    # è¿è¡Œç»„ä»¶æ—¶é—´æµ‹è¯•
    test_flow_smooth_loss_components()
    
    # è¿è¡Œå†…å­˜æµ‹è¯•
    test_flow_smooth_loss_memory()
    
    # è¿è¡ŒæŸå¤±å‡½æ•°æ¯”è¾ƒæµ‹è¯•
    test_flow_smooth_loss_vs_other_losses()
    
    print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ / All tests completed!") 